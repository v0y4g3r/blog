<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Database on Tokamako</title>
    <link>https://huanglei.rocks/tags/database/</link>
    <description>Recent content in Database on Tokamako</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Sat, 12 Mar 2022 17:42:25 +0800</lastBuildDate><atom:link href="https://huanglei.rocks/tags/database/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Notes on InfluxDB Storage Engine</title>
      <link>https://huanglei.rocks/posts/notes-on-influxdb-storage/</link>
      <pubDate>Sat, 12 Mar 2022 17:42:25 +0800</pubDate>
      
      <guid>https://huanglei.rocks/posts/notes-on-influxdb-storage/</guid>
      <description>InfluxDB 的存储引擎经过多次修改，本文描述的系统结构基于 InfluxDB 截止 2022-02-24 的 adf29dfedfc785620db0e104652544ce9f67cb6e 版本。当前版本已经支持 TSI 索引结构。
  InfluxDB 的存储系统   InfluxDB 的存储层有三个子系统：
 TSM：数据点的存储，可以高效地提供 SeriesKey 到时序数据值的插入和检索； TSI：时序数据的倒排索引，提供查询某个 measurement 下某个 tag 包含特定值的 SeriesID 的接口；  TSI 是 InfluxDB 查询引擎的核心，所谓的基数膨胀带来的问题也是出现在这一层。 为了降低 TSI 的内存占用，InfluxDB 引入了一个额外的 SeriesID。   Series 索引：提供根据 SeriesID 查找 SeriesKey 的接口等  SeriesFile.CreateSeriesListIfNotExists：创建 SeriesKey-&amp;gt;SeriesID 的映射 SeriesFile.SeriesKey：根据 SeriesID 查找 SeriesKey    应该说 TSI 加上 SeriesIndex 才是 InfluxDB 完整的索引部分，但是这两者各自是一个类 LSMT 的数据结构，也有自己的 WAL、compaction/recover 策略等等，因此 InfluxDB 做了区分。</description>
    </item>
    
    <item>
      <title>Apache Parquet 格式简介</title>
      <link>https://huanglei.rocks/posts/parquet/</link>
      <pubDate>Sat, 05 Mar 2022 15:44:33 +0800</pubDate>
      
      <guid>https://huanglei.rocks/posts/parquet/</guid>
      <description>简介 Parquet 是一种面向列的数据存储格式，在 Hadoop 生态中使用广泛。Parquet 文件是不可变的，如果需要修改，只能通过 rewrite 的方式实现。
数据 layout 一个 Parquet 文件的数据布局如下图所示。需要注意的是，官网上的这个图并没有包含 index pages。
 官方的格式图    原始行格式的数据    Parquet 数据的遍历顺序    使用 Parquet 转换之后的格式   在 Parquet 中，数据每隔若干行被分作一个 row group；在同一个 row group 中，不同 row 的相同列被连续存储在一起。连续的列再间隔若干行会被分割为一个页（page）。
元数据 从如上的 Parquet 格式可以看出来，一个 Parquet 文件是包含了一些元数据的，比如 footer、page header 等等，这些元数据可以在读取 parquet 文件的时候提供相关信息来加速遍历。
Footer Footer 是整个 Parquet 文件的元数据，从 footer 可以得到文件的版本、数据 schema、row group 的元数据、row group 中的每一列的元数据等等。
Footer 位于 Parquet 的末尾，因此可以从文件结尾 seek 到倒数第 8 到倒数第 4 字节，作为 footer 的长度，从而得到 footer 区的起始 offset。</description>
    </item>
    
    <item>
      <title>LSM Tree 笔记</title>
      <link>https://huanglei.rocks/posts/note-on-lsmt/</link>
      <pubDate>Thu, 10 Feb 2022 22:34:39 +0800</pubDate>
      
      <guid>https://huanglei.rocks/posts/note-on-lsmt/</guid>
      <description>写入（Write path）   先从磁盘（HDD）写入的特性引入 append-only 的 WAL。
  对于 KV 结构，如果写入是 append only的，那么就需要合并，不然读取性能太差。
  单文件合并性能差，因此需要按阈值切分为多个小文件，通过归并排序的思路优化合并的效率。
  多路归并要求每个文件有序，为了保证每个文件有序，就需要，数据写入的时候，不直接把 operation 直接写入到磁盘，而是先在内存缓存一段时间，并且在内存排好序，然后再一次把整个文件 flush 到磁盘。
 内存有序的数据结构：跳表、红黑树、B+ 树 buffer 在内存的数据丢了怎么办？先写 redo log    有序数据结构  RocksDB 的数据结构比较：选择跳表的原因是跳表支持并发插入。
 LSMT 的数据分类
 内存数据：MemTable 磁盘数据：SSTable（Sorted Sequence Table） 日志：redo log  内存数据组织 内存的数据需要保证有序，同时支持高性能的插入和查找。
 ART：自适应基树（比如 Bitcask 采用）； SkipList：LevelDB、RocksDB 等。  SSTable 文件格式 按 Block 进行存储，可以参考 LevelDB 和 RocksDB 的 SST 文件的格式。</description>
    </item>
    
  </channel>
</rss>
